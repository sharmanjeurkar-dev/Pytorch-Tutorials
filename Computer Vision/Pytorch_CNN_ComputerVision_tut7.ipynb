{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Convolutional Neural Networks (CNN)\n",
    "- Known for their abilities to find patterns in visual data.\n",
    "- It follows the typical structure of a convolutional neural network:\n",
    "\n",
    "Input layer -> [Convolutional layer -> activation layer -> pooling layer] -> Output layer\n",
    "- Where the contents of [Convolutional layer -> activation layer -> pooling layer] can be upscaled and repeated multiple times, depending on requirements.\n"
   ],
   "id": "6f954920812b91f5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T17:23:41.474713Z",
     "start_time": "2025-10-02T17:23:22.429310Z"
    }
   },
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:23:41.717439Z",
     "start_time": "2025-10-02T17:23:41.537576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup training data\n",
    "train_dataset = datasets.FashionMNIST(root='./data',\n",
    "                                      train=True, # get the train data\n",
    "                                      download=True,\n",
    "                                      transform=ToTensor(),\n",
    "                                      target_transform=None)\n",
    "\n",
    "# Setup testing data\n",
    "test_dataset = datasets.FashionMNIST(root='./data',\n",
    "                                     train=False, # get the test data and not train data\n",
    "                                     download=True,\n",
    "                                     transform=ToTensor())"
   ],
   "id": "3035ee1cc3ef75b4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:28:09.776182Z",
     "start_time": "2025-10-02T17:28:09.619200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes= train_dataset.classes\n",
    "classes"
   ],
   "id": "6b6965bfa6e1d42e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:28:39.549161Z",
     "start_time": "2025-10-02T17:28:39.481377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creation of dataloader\n",
    "\n",
    "#Set the batch size\n",
    "batch_size = 32\n",
    "\n",
    "#Load the training data\n",
    "train_dataloader = DataLoader(\n",
    "                              train_dataset, #load the data\n",
    "                              batch_size=batch_size, # samples per batch\n",
    "                              shuffle=True # shuffle data every epoch\n",
    "                              )\n",
    "\n",
    "#Load the testing data\n",
    "test_dataloader = DataLoader(\n",
    "                              test_dataset, #load the data\n",
    "                              batch_size=batch_size, # samples per batch\n",
    "                              shuffle=False # shuffle data every epoch is not necessary\n",
    "                              )\n",
    "len(train_dataloader),len(test_dataloader) # give u size of each batch"
   ],
   "id": "dfcafe71fd7ac48e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 313)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:29:33.201338Z",
     "start_time": "2025-10-02T17:29:33.166509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup device agnostic code\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "id": "aa1d48695ada1b5f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:29:35.159285Z",
     "start_time": "2025-10-02T17:29:35.015648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss_total, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, Y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        train_predcition = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        train_loss = loss_fn(train_predcition, Y)\n",
    "        train_loss_total+= train_loss\n",
    "        train_acc += accuracy_fn(y_true=Y,\n",
    "                                 y_pred=train_predcition.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        train_loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss_total /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss_total:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss_total, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        for X, Y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss_total += loss_fn(test_pred, Y)\n",
    "            test_acc += accuracy_fn(y_true=Y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss_total /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss_total:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ],
   "id": "23c7f1ebc26864aa",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:09:40.541913Z",
     "start_time": "2025-10-02T18:09:40.388614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CNN model\n",
    "class Model_CNN(nn.Module):\n",
    "    def __init__(self,in_features,out_features,hidden_units):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_features,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3, #how big square should be\n",
    "                      stride=1, #\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*7*7,\n",
    "                      out_features=out_features),\n",
    "        )\n",
    "\n",
    "    #Forward Pass\n",
    "    def forward(self,x:torch.Tensor):\n",
    "        x = self.block1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.block2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ],
   "id": "66cf7f557a955ca2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hyper Parameters of CNN Architecture\n",
    "These are the parameters which are set by the us. The in_channel symbolises the input channels that is the dimension eg. [grey_scale:1, height:28, width:28] means in_channels are 3 same as that in Linear. The out_channels are the number of the filters out of which is the classification is to be undertaken same as that of Linear. Hidden units are neurons which are created by the model for better visualization of data again same as that of Linear. In CNN the major change happens in the way the data is visualized. All the data and pixels are visualized in the form of gird. The in_channels tell the neural network to form a grid of that many squares. Padding tells, how many squares to be added outside the in_channel grid. The data visualization happens in the grid format itself. The grid size is decided as per the value of kernels. If kernel is set as 3 then it would form a (3,3) grid. Strid tell the model how many squares to jump while observing and inferring the patterns. This all takes places in nn.Conv2d, where 2d used in this means that the image data is 2 dimensional i.e. only height and width is present.. This data is then passed in it also has the non-linearity factor  set. Every collection  sequential layer on nn.Conv2d is called a block of layers or only block.After every CNN layer Pooling takes place where the maximum useful data is pooled out of the image. Then this data is passed on to linear layer where nn.Flatten is  added.This is a crucial step that converts the 2D feature maps into a single long 1D vector. This vector is then passed to the final nn.Linear layers, where the out_features of the very last linear layer must match the number of classes you are predicting.Essentially, every layer in a neural network is trying to compress data from higher dimensional space to lower dimensional space."
   ],
   "id": "a54581bee4dc8900"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Formula\n",
    "The formula to calculate the output height or width is the same for both Conv2d and MaxPool2d:\n",
    "\n",
    "Output_Size = floor( (Input_Size - Kernel_Size + 2 * Padding) / Stride ) + 1\n",
    "\n",
    "Let's apply this to your Model_CNN architecture.\n",
    "\n",
    "## Applying the Formula to Your Project\n",
    "Your input images from FashionMNIST have a shape of [batch, 1, 28, 28].\n",
    "\n",
    "After block1:\n",
    "Input Shape: 28x28\n",
    "\n",
    "First Conv2d: (28 - 3 + 2*1)/1 + 1 = 28. Output is 28x28.\n",
    "\n",
    "Second Conv2d: (28 - 3 + 2*1)/1 + 1 = 28. Output is 28x28.\n",
    "\n",
    "MaxPool2d: (28 - 2 + 2*0)/2 + 1 = 14. Output is 14x14.\n",
    "\n",
    "Resulting Shape: [batch, 10, 14, 14] (This is your first output torch.Size([32, 10, 14, 14]))\n",
    "\n",
    "After block2:\n",
    "Input Shape: 14x14\n",
    "\n",
    "First Conv2d: (14 - 3 + 2*1)/1 + 1 = 14. Output is 14x14.\n",
    "\n",
    "Second Conv2d: (14 - 3 + 2*1)/1 + 1 = 14. Output is 14x14.\n",
    "\n",
    "MaxPool2d: (14 - 2 + 2*0)/2 + 1 = 7. Output is 7x7.\n",
    "\n",
    "Resulting Shape: [batch, 10, 7, 7] (This is your second output torch.Size([32, 10, 7, 7]))\n",
    "\n",
    "## Calculating the in_features for the Linear Layer\n",
    "To get the number for your nn.Linear layer's in_features, you multiply the dimensions of the output from the last convolutional/pooling block (channels * height * width).\n",
    "\n",
    "Calculation: 10 * 7 * 7 = 490\n",
    "\n",
    "This number, 490, is the length of the vector after nn.Flatten is applied, and it's the exact in_features your nn.Linear layer needs."
   ],
   "id": "d6a9affaf9734910"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:11:09.853469Z",
     "start_time": "2025-10-02T18:11:09.580011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Instance of model\n",
    "\n",
    "model = Model_CNN(in_features=1,\n",
    "                  hidden_units=10,\n",
    "                  out_features=len(classes))\n",
    "model"
   ],
   "id": "c53ee14d3622d378",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_CNN(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(784, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:51:15.938557Z",
     "start_time": "2025-10-02T18:51:15.716508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loss Function, accuracy function and Optimizer\n",
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.01)"
   ],
   "id": "d1b5b08df129c637",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'---------Epoch: {epoch + 1}--------- \\n')\n",
    "    train_step(model = model,\n",
    "               data_loader = train_dataloader,\n",
    "               optimizer=optimizer,\n",
    "               loss_fn=loss_fn,\n",
    "               accuracy_fn=accuracy_fn)\n",
    "    test_step(model = model,\n",
    "              data_loader = test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn)"
   ],
   "id": "f2a77dda4661bb8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T16:58:42.703296Z",
     "start_time": "2025-10-03T16:58:42.685212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # Prepare sample\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
    "\n",
    "            # Forward pass (model outputs raw logit)\n",
    "            pred_logit = model(sample)\n",
    "\n",
    "            # Get prediction probability (logit -> prediction probability)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 1, so can perform on dim=0)\n",
    "\n",
    "            # Get pred_prob off GPU for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    # Stack the pred_probs to turn list into a tensor\n",
    "    return torch.stack(pred_probs)"
   ],
   "id": "571f6307f1aa604b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T16:59:17.575391Z",
     "start_time": "2025-10-03T16:59:13.368172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in random.sample(list(test_dataset), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# View the first test sample shape and label\n",
    "print(f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({classes[test_labels[0]]})\")"
   ],
   "id": "ac4f43af76c8e2e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample image shape:  torch.Size([1, 28, 28])\n",
      "Test sample labels: 1 (Trouser)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Make predictions on test samples with model 2\n",
    "pred_probs= make_predictions(model=model,\n",
    "                             data=test_samples)\n",
    "\n",
    "# View first two prediction probabilities list\n",
    "pred_probs[:2]"
   ],
   "id": "845c62bf5c8652a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ],
   "id": "d62db1cea3898e56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_labels,pred_classes",
   "id": "b696f59c61443158"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(9, 9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "  # Create a subplot\n",
    "  plt.subplot(nrows, ncols, i+1)\n",
    "\n",
    "  # Plot the target image\n",
    "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "\n",
    "  # Find the prediction label (in text form, e.g. \"Sandal\")\n",
    "  pred_label = classes[pred_classes[i]]\n",
    "\n",
    "  # Get the truth label (in text form, e.g. \"T-shirt\")\n",
    "  truth_label = classes[test_labels[i]]\n",
    "\n",
    "  # Create the title text of the plot\n",
    "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "\n",
    "  # Check for equality and change title colour accordingly\n",
    "  if pred_label == truth_label:\n",
    "      plt.title(title_text, fontsize=10, c=\"g\") # green text if correct\n",
    "  else:\n",
    "      plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
    "  plt.axis(False);"
   ],
   "id": "b5d17477ccc6746d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
